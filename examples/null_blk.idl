module kernel {

	rpc_ptr void release( projection disk * [unused] disk, u32 [unused] mode ) {
		projection < struct gendisk > disk {
		}
	}

	rpc int register_blkdev( unsigned int major, string [alloc(callee)] *name ) {
	}

	rpc void del_gendisk( projection disk * disk ) {
		projection < struct hd_struct> hd_struct{
			u64 [out] nr_sects;
		}
		projection < struct gendisk > disk {
			projection hd_struct part0;
			//int [out] flags;
		}
	}
	rpc void device_add_disk( projection parent * [unused] parent, projection disk * disk ) {
		projection < struct device > parent {
			//rpc_ptr release release;
		}
		projection < struct hd_struct> hd_struct{
			u64 nr_sects;
		}
		projection < struct gendisk > disk {
			int [out, in] major;
			int [out, in] first_minor;
			array<char, 32> disk_name;
			projection hd_struct part0;
			projection fops [alloc(callee)] * fops;
			projection queue* queue;
			int [out, in] flags;
		}
		projection < struct request_queue > queue {
		}
		projection < struct block_device_operations > fops {
			rpc_ptr open open;
			rpc_ptr release release;
		}
	}

	rpc void blk_cleanup_queue( projection q * q ) {
		projection < struct request_queue > q {
			// FIXME: shared_lock! Need synchronization rpcs
			//projection queue_lock* queue_lock;	
		}
		projection < struct spinlock > queue_lock {
		}
	}
	rpc void blk_mq_end_request( projection rq * rq, int error ) {
		projection < struct request > rq {
			//projection q* q;
			int errors;
		}
		projection < struct request_queue > q {
		}
	}

	rpc_ptr void complete( projection rq [bind(callee)] * rq ) {
		projection < struct request > rq {
			//void*  special;
		}
	}

	rpc_ptr int open( projection bdev * [unused] bdev, u32 mode ) {
		projection < struct block_device > bdev {
		}
	}

	rpc projection ret_gendisk [alloc(caller)] * alloc_disk_node( int minors, int node_id ) {
		projection < struct hd_struct> hd_struct{
		}
		projection < struct gendisk > ret_gendisk {
			projection hd_struct part0;
		}
	}

	rpc_ptr int queue_rq( projection hctx [bind(callee)] * hctx,
			projection bd [alloc(callee)] * bd ) {
		projection < struct blk_mq_hw_ctx > hctx {
		}
		projection < struct blk_mq_queue_data > bd {
			// FIXME: Need an explicit copy annotation?
			//projection rq [alloc<{{sizeof(struct request) + sizeof(struct nullb_cmd)}}>(callee)] * rq;
			projection rq [alloc<{{sizeof(struct request) + sizeof(struct __nullb_cmd)}}>(callee)] * rq;
		}
		projection < struct request > rq {
		}
	}
	rpc_ptr int init_hctx( projection hctx [alloc(callee)] * hctx,
			void * data, unsigned int index ) {
		projection < struct blk_mq_hw_ctx > hctx {
		}
	}

	rpc_ptr projection blk_mq_hw_ctx [bind(callee)] *map_queue(projection rq [alloc_once(callee)] *rq,
					const int cpu) {
		projection < struct blk_mq_hw_ctx > blk_mq_hw_ctx {
		}
		projection < struct request_queue > rq {
		}
	}

rpc_ptr s32 set( s8* str, projection kp * kp ) {
	projection < struct kernel_param > kp {
	}
}
/*rpc void __raw_spin_lock_init( projection lock * lock, s8* name, projection key * key ) {
	projection < struct raw_spinlock > lock {
	}
	projection < struct lock_class_key > key {
	}
}
rpc void _raw_spin_unlock_irq( projection lock * lock ) {
	projection < struct raw_spinlock > lock {
	}
}*/
rpc s32 param_get_int( char* buffer, const projection kp * kp ) {
	projection < struct kernel_param > kp {
	}
}
rpc void prepare_to_wait( projection q * q, projection wait * wait, s32 state ) {
	projection < struct __wait_queue_head > q {
	}
	projection < struct __wait_queue > wait {
		u32 [out] flags;
	}
}
rpc void finish_wait( projection q * q, projection wait * wait ) {
	projection < struct __wait_queue_head > q {
	}
	projection < struct __wait_queue > wait {
	}
}
rpc s32 autoremove_wake_function( projection wait * wait, u32 mode, s32 sync, void* key ) {
	projection < struct __wait_queue > wait {
	}
}

	rpc void unregister_blkdev( unsigned int major, string [alloc(callee)] *name ) {
	}

	rpc void put_disk( projection disk * disk ) {
		projection < struct hd_struct> hd_struct{
		}
		projection < struct gendisk > disk {
			projection hd_struct part0;
		}
	}


	/* XXX: Not needed for our null_blk configuration
	rpc projection ret_request_queue* blk_init_queue_node( rpc_ptr rfn rfn, projection lock * lock, s32 node_id ) {
		projection < struct request_queue > ret_request_queue {
		}
		projection < struct spinlock > lock {
		}
	}
	rpc projection ret_request_queue* blk_alloc_queue_node( u32 gfp_mask, s32 node_id ) {
		projection < struct request_queue > ret_request_queue {
			projection queue_lock* queue_lock;
		}
		projection < struct spinlock > ret_queue_lock {
		}
	}
	rpc void blk_end_request_all( projection rq * rq, s32 error ) {
		projection < struct list_head> list_head{
		}
		projection < struct request > rq {
			projection list_head queuelist;
			projection q* q;
			s32  errors;
		}
		projection < struct request_queue > q {
			u64  queue_flags;
		}
	}
	rpc projection ret_request* blk_fetch_request( projection q * q ) {
		projection < struct request > ret_request {
		}
		projection < struct request_queue > q {
		}
	}
	rpc void blk_complete_request( projection req * req ) {
		projection < struct request > req {
			projection q* q;
		}
		projection < struct request_queue > q {
		}
	}

	rpc void hrtimer_start_range_ns( projection timer * timer, ktime tim,
			u64 delta_ns, u32 mode ) {
		projection < struct hrtimer > timer {
		}
		projection < struct ktime > tim {
		}
	}
	rpc void hrtimer_init( projection timer * timer, s32 clock_id, u32 mode ) {
		projection < struct hrtimer > timer {
		}
	}
	rpc void blk_queue_make_request( projection q * q, rpc_ptr mfn mfn ) {
		projection < struct request_queue > q {
		}
	}
	rpc void blk_stop_queue( projection q * q ) {
		projection < struct request_queue > q {
		}
	}
	rpc void blk_start_queue_async( projection q * q ) {
		projection < struct request_queue > q {
		}
	}
	rpc void blk_queue_prep_rq( projection q * q, rpc_ptr pfn pfn ) {
		projection < struct request_queue > q {
		}
	}
	rpc void blk_queue_softirq_done( projection q * q, rpc_ptr fn fn ) {
		projection < struct request_queue > q {
		}
	}
	*/

	rpc void blk_mq_free_tag_set( projection set [bind(callee)] * set ) {
		projection < struct blk_mq_tag_set > set {
		}
	}

	rpc int blk_mq_alloc_tag_set( projection set [alloc(callee)] * set ) {
		projection < struct blk_mq_tag_set > set {
			projection _global_blk_mq_ops [alloc(callee)] * ops;
			unsigned int [in, out] nr_hw_queues;
			unsigned int [in, out] queue_depth;
			unsigned int cmd_size;
			unsigned int [in, out] flags;
			int numa_node;
			//array<projection tags,{{ctx->set->nr_hw_queues}}> [alloc(caller)] **tags;
			void [alloc<{{sizeof(void*)}}>(callee)] *driver_data;
		}
		projection <struct blk_mq_tags> tags {
			array<projection request, {{ctx->set->queue_depth}}> **rqs;
			int alloc_policy;
			unsigned int nr_tags;
			unsigned int nr_reserved_tags;
		}
		projection <struct request> request {

		}
	}

	rpc projection ret_request_queue [alloc(caller)] *
			blk_mq_init_queue( projection set [bind(callee)] * set ) {
		projection < struct request_queue > ret_request_queue {
			// TODO: Alloc here or in init_hctx?
			// I think init_hctx is called in this context
			//array<projection hw_ctx*,{{ctx->set->queue_depth}}> [alloc(caller)] *queue_hw_ctx;
		}
		projection < struct blk_mq_tag_set > set {
			s32  numa_node;
		}
	}

	rpc projection ret_blk_mq_hw_ctx [bind(caller)] * blk_mq_map_queue( projection q * q, s32 cpu ) {
		projection < struct blk_mq_hw_ctx > ret_blk_mq_hw_ctx {
		}
		projection < struct request_queue > q {
		}
	}

	rpc void blk_mq_start_request( projection rq * rq ) {
		projection < struct request > rq {
			//projection q* q;
		}
		projection < struct request_queue > q {
		}
	}

	rpc void blk_mq_complete_request( projection rq * rq, int error ) {
		projection < struct request > rq {
			//projection q* q;
			int [out] errors;
		}
		projection < struct request_queue > q {
		}
	}

	rpc void blk_queue_physical_block_size( projection q * q, u32 size ) {
		projection < struct request_queue > q {
		}
	}

	rpc void blk_queue_logical_block_size( projection q * q, u16 size ) {
		projection < struct request_queue > q {
		}
	}

	projection < struct blk_mq_ops > _global_blk_mq_ops {
		rpc_ptr complete complete;
		rpc_ptr init_hctx init_hctx;
		rpc_ptr map_queue map_queue;
		rpc_ptr queue_rq queue_rq;
	}
}
